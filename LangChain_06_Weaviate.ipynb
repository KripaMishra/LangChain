{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWqqpfVLp3dtXE8tjz17tx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KripaMishra/LangChain/blob/main/LangChain_06_Weaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wA3AmdvZPJ5",
        "outputId": "a3618eb0-f5f3-41b2-9bc0-b71b4452d4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.5.4-py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.31.0)\n",
            "Collecting httpx==0.27.0 (from weaviate-client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting validators==0.22.0 (from weaviate-client)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.6.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.62.1)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.62.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx==0.27.0->weaviate-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx==0.27.0->weaviate-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (42.0.5)\n",
            "Collecting protobuf>=4.21.6 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (67.7.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.0->weaviate-client) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
            "Installing collected packages: validators, protobuf, h11, httpcore, grpcio-tools, grpcio-health-checking, httpx, authlib, weaviate-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.0 grpcio-health-checking-1.62.1 grpcio-tools-1.62.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 protobuf-4.25.3 validators-0.22.0 weaviate-client-4.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETtsr_AaZa58",
        "outputId": "05734d01-3924-492f-8a0e-01564d682871"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.38 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.16.1-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "OG3hgl3UZf7u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "U3J9t5jFZxLu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEAVIATE_API_KEY = \"G4km7Z7QPHQmZ9HB9UzI15QhCcEUIo9iFUlt\"\n",
        "WEAVIATE_CLUSTER = \"https://first-j14jeqde.weaviate.network\""
      ],
      "metadata": {
        "id": "EYQfBAP-Z9N4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "steps to setup:\n",
        "- Create a cluster and go the details button\n",
        "- Copy the cluster URL\n",
        "- Generate a KEY and save it."
      ],
      "metadata": {
        "id": "Kci0vcGybTh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data"
      ],
      "metadata": {
        "id": "Rgfu8WTTcTsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCc1xT_uctKS",
        "outputId": "f6712951-f434-41ed-c948-5ed143ebe44e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "3L2RSoUObTSi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "loader=PyPDFDirectoryLoader(\"data\")"
      ],
      "metadata": {
        "id": "e0UNwIfwZymU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=loader.load()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-31GBXFkZyjl",
        "outputId": "1b0c87c2-ae72-4c43-d4be-18841228f33b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='In this course you are going to learn the absolute basics of Kubernetes. \\n1Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudkubernetes\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 0}),\n",
              " Document(page_content=\"We'll start with a quick introducCon to containers, and then we'll understand why you need container orchestraCon, what Kubernetes is, and then dive into Kubernetes concepts such as Pods, ReplicaSets, Deployments, Services and ﬁnally a project on deploying a micro-services applicaCon to a Kubernetes cluster. \\n2Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nContainers\\nKubernetes\\nKubernetes Cluster\\nPods\\nReplicaSets\\nDeployments\\nServices\\nProject\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 1}),\n",
              " Document(page_content=\"So here's how I recommend you to take this course. This course is about 2 hours of video and 2 hours of lab time. By the end of this course you should aim to get a high level understanding of Kubernetes, not just theory but with hands-on practice. \\n3Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n~2 Hours\\n~2 Hours\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 2}),\n",
              " Document(page_content='Each concept taught in this video\\n4Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nContainers\\nKubernetes\\nKubernetes Cluster\\nPods\\nReplicaSets\\nDeployments\\nServices\\nDemo Application', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 3}),\n",
              " Document(page_content='is followed by hands-on labs. \\n5Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nContainers\\nKubernetes\\nKubernetes Cluster\\nPods\\nReplicaSets\\nDeployments\\nServices\\nDemo Application\\nLabs\\nLabs\\nLabs\\nLabs\\nLabs\\nLabs\\nLabs\\nLabs', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 4}),\n",
              " Document(page_content=\"Let's start by refreshing our memory on containers. \\n6Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudWhat are Containers?\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 5}),\n",
              " Document(page_content='So before we begin, head over to this link to download the deck used in this course, so you can keep a local copy for your own reference, as well as to access the labs that comes free with this course. Go to kode.wiki/kubernetes-labs. Or scan this QR code. \\n7Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudhttps://kode.wiki/kubernetes-labs\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 6}),\n",
              " Document(page_content=\"Let's start by refreshing our memory on containers. \\n8Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudWhat are Containers?\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 7}),\n",
              " Document(page_content=\"So that's you and you are developing an application on your laptop. Say it's written in Python. It has certain dependencies such as the flask framework for serving a website.  You are also working on another part of the application –say a payment service that also uses the flask framework, but relies on a different version of the library. \\n9Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.2.0flask==2.1.0\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 8}),\n",
              " Document(page_content=\"ApplicaCons typically add many such packages as they grow. And they may all be diﬀerent in diﬀerent applicaCons. That's going to be a challenge if you are trying to run the same applicaCon on the same machine. Now certain programming languages provide soluCons to tackle these. For example Python has the Python Virtual Environments concept that helps isolate python packages into virtual environments. That way you can have diﬀerent versions of dependencies in diﬀerent virtual environments. However that doesn't help you separate dependencies outside of the programming language libraries. For example, your app may rely on a speciﬁc package on the operaCng system, such as a \\n10Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 9}),\n",
              " Document(page_content=\"say the glib system library or utilities like curl. What if your application relies on certain binaries and packages on the system that require different versions? It's going to be hard to manage different versions of dependencies on the same OS.Moreover, let's say you bring in a friend to help you develop the application. \\n11Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 10}),\n",
              " Document(page_content=\"That person need to setup the exact same environment in the exact same way with the exact same versions of dependencies and libraries. And if the other person uses a completely different operating system, then a whole different nightmare awaits. Now you'll need to figure out what the different dependencies are for that operating system.Now we have only been talking about development environment. \\n12Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4development\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 11}),\n",
              " Document(page_content=\"What happens when the application is deployed to a test environment or to a production environment. You'll have to make sure you setup the environment in the exact same way with the exact same dependencies. If you change something in the <c> development environment you'll have to make sure it gets updated in the test and prod environments.<c>  Otherwise things end up working in one environment and not working in the other. And no matter how much you try it's impossible to make sure these environments remain the same. At some point in time, someone is going to make a change to a dependency or add another dependency and forget to update them in the other environments and things are going to break. \\n13Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4development\\nproduction\\ntestflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4dnspython==2.0\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 12}),\n",
              " Document(page_content='What if you could build an image that consists of the app itself and all  of its dependencies at both the app level and system level and package it… \\n14Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1glib==2.37glib==1.3curl==7.88curl==5.4development\\nproduction\\ntestflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4building…\\nbuild\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 13}),\n",
              " Document(page_content='And use the same exact image in all of the different environments? <c> That way anytime you make a change in the future, the image is rebuilt…\\n15Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1glib==2.37glib==1.3curl==7.88curl==5.4development\\nproduction\\ntestflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4dnspython==2.0building…\\nbuildflask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 14}),\n",
              " Document(page_content=\"and the same image is used in all of the different environments. No more differences between different environments. So that's what containers can help us with. \\n16Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1glib==2.37glib==1.3curl==7.88curl==5.4development\\nproduction\\ntestdnspython==2.0flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 15}),\n",
              " Document(page_content='Containers help us create isolated environments on our systems to run applications completely isolated from each other. <c> You could run a different web application with different versions of dependencies or a PostgreSQL server or a MySQL server or Redis server. All on the same system with their own libraries and dependencies. But not worrying about any impact to each other.  Each of these maybe based on different operating systems too. \\n17Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudflask==2.1.0\\ncycler==0.11.0dnspythonffmpegglib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspythonffmpegglib==1.3curl==5.4\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4development\\ntestdnspython==2.0flask==2.1.0\\ncycler==0.11.0dnspython==2.0ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0cycler==0.10.0dnspython==2.0ffmpeg==1.4glib==2.37curl==7.88\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 16}),\n",
              " Document(page_content='Containers allow you to build images based on specific operating systems, then add all system level and application level dependencies to it to finally have a lean and clean image for each application that can run anywhere. On your linuxmachine you can run any of these applications even if they are based on a different OS flavor. \\n18Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudflask==2.1.0\\ncycler==0.11.0dnspythonffmpegglib==1.3curl==5.4flask==2.1.0\\ncycler==0.11.0dnspythonffmpegglib==1.3curl==5.4\\nflask==2.1.0\\ncycler==0.11.0dnspython==1.9ffmpeg==1.1glib==1.3curl==5.4\\nflask==2.2.0flask==2.1.0\\ncycler==0.10.0cycler==0.11.0dnspython==2.0dnspython==1.9ffmpeg==1.4ffmpeg==1.1\\nglib==2.37glib==1.3curl==7.88curl==5.4development\\ntestdnspython==2.0\\nflask==2.2.0cycler==0.10.0dnspython==2.0ffmpeg==1.4glib==2.37curl==7.88\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…\\ndep1…dep2…dep3…dep4…sys_pkg_1…sys_pkg_2…ubuntu\\nsuse\\nredhat\\nubuntu\\nredhat\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 17}),\n",
              " Document(page_content='And one of the most popular tools to containerize applications and run containers is Docker. \\n19Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 18}),\n",
              " Document(page_content=\"So here we have our application code, the requirements.txtfile with the list of dependencies and we now build a Dockerfileto package the application with it's dependencies into a Docker container.<c> The first line creates an image from the python base image. <c>  Then sets the right working directory. <c>  Then copies the requirements.txtfile to the working directory. <c>  And then installs the dependencies. This is where you could add any other 20Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n>_$docker build ....\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 19}),\n",
              " Document(page_content='dependency to it<c> And then copies the application code into the image. <c> And finally defines the command to run the application using the CMD instruction.Now by running the docker build command we build an image. 31/03/23\\n20', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 20}),\n",
              " Document(page_content='and by running the docker run command we run one instance of our application. So that was a quick introduction to containers and Docker. \\n21Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$docker run ....\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 21}),\n",
              " Document(page_content=\"If you are new to Docker I would recommend checking out our free Docker for Beginners course on KodeKloudusing the link given here. You'll learn with hands-on labs using our interactive learning environment by working on real systems exclusive to you. \\n22Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudhttps://kode.wiki/kubernetes-labs\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 22}),\n",
              " Document(page_content='At any time during this course if you feel you need assistance, head over to our community group. We have a thriving community on slack where our instructors and teaching assistances hang out. So go to kode.wiki/community or scan this QR code to get an invite. Explore the various channels available for learning different topics and feel free to post your questions in the respective channels.\\n23Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudhttps://kode.wiki/community\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 23}),\n",
              " Document(page_content='So we have learned about containers, let us now see what Container Orchestration is.\\n24Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudWhat is Container Orchestration?', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 24}),\n",
              " Document(page_content=\"By running the docker run command we were able to run one instance of our applicaCon. This instance can serve one set of users. <c> But what if users increase? We want to be able to run more instances. <c> If one instance crashes for some reason we want it to be able to automaCcally restart. If there isn't enough resources on the server, we want to be able to scale out by adding more servers.  And then run more instances of our applicaCon on those servers. <c> And when users decrease, we want to be able to remove instances and reduce the number of servers. So that's what container orchestraCon is at a high level. We want to be able to orchestrate mulCple containers to scale up or down and also deﬁne the relaCon ship between the containers declaraCvely. 25Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$docker run ....\\n$docker run ....$docker run ....\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 25}),\n",
              " Document(page_content='<c> If our app is dependent upon on a database container orchestrators can help us define that relationship. 31/03/23\\n25', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 26}),\n",
              " Document(page_content='There are different container orchestration solutions out there today –such as Docker Swarm, Kubernetes,  Mesos and now Nomad to name a few.  Kubernetes is the most popular of it all and \\n26Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nkubernetes\\nDocker Swarm', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 27}),\n",
              " Document(page_content='In the rest of the video we will focus on Kuberentes. \\n27Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nkubernetes\\nDocker Swarm', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 28}),\n",
              " Document(page_content='So what is Kubernetes?\\n28Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nkubernetes\\nDocker Swarm', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 29}),\n",
              " Document(page_content=\"With docker you were able to run a single instance of an application using the docker run command. Which is great! Running an application has never been so easy before. With kubernetes, using the kubernetesCLI known as kubectl, <c> you can run a 1000 instance of the same application with a single command. <c> Kubernetes can scale it up to 2000 with another command.Kubernetes can even be configured to do these automatically so that instances and the infrastructure itself can scale up and down based on user load.<c> Kubernetes can upgrade these 2000 instances of application in a rolling fashion one at a time, with a single command. <c> If something goes wrong, it can help you roll back these images with a single command. <c> Kubernetes can help you test new features of your application by only upgrading a percentage of these instances through A/B testing methods. Don't worry about the command line tool for now. We will take a closer look at it soon. 29Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$docker run ....\\n>_$kubectlrun -–replicas=1000 my-web-server\\n$kubectlscale -–replicas=2000 my-web-server\\n$kubectlrolling-updatemy-web-server --image=web-server:2\\n$kubectlrolling-update my-web-server --rollback\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 30}),\n",
              " Document(page_content='With Kubernetes you are able to define the expected state of your application. For example you are able to define that your application consists of 4 different services. The webserver must have 3 instances running, the payment service to have 2. There should be a redisservice with 3 instances running and a database service to which these services connect to. And you are able to define these in code and Kubeneteswill ensure that the state you have defined for your application is maintained at all times. \\n30Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 31}),\n",
              " Document(page_content=\"Let's us understand the basic components in a Kubernetes Cluster first. Let us start with Nodes. A node is a machine –physical or virtual –on which kubernetesis installed. A node is a worker machine and this is were containers will be launched by kubernetes. <click>But what if the node on which our application is running fails? Well, obviously our application goes down. So you need to have more than one nodes. <click>\\n31Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nNode\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 32}),\n",
              " Document(page_content='<click>A cluster is a set of nodes grouped together. This way even if one <c> node fails you have your application still accessible from the other nodes. Moreover having multiple nodes helps in sharing load as well.Now we have a cluster, but who is responsible for managing the cluster? Were is the information about the members of the cluster stored? How are the nodes monitored? When a node fails how do you move the workload of the failed node to another worker node? That’s were the ControlPlanecomes in. Also previously known as the master node.\\n32Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nNode\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 33}),\n",
              " Document(page_content='The controlplaneis another node with Kubernetes components installed in it.   The controlplanewatches over the nodes in the cluster and is responsible for the actual orchestraCon of containers on the worker nodes. \\n33Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nCluster\\nControlPlaneWorkerWorkerWorker', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 34}),\n",
              " Document(page_content='When you install Kubernetes on a System, you are actually installing the following components. An API Server. An ETCD service. Controllers and Schedulers.The API server acts as the front-end for kubernetes. The users, management devices, Command line interfaces all talk to the API server to interact with the kubernetescluster.Next is the ETCD key store. ETCD is a distributed reliable key-value store used by kubernetesto store all data used to manage the cluster. This is where information about the nodes in the cluster, the application running on the cluster are stored.<click><click>The controllers are the brain behind orchestration. They are responsible for noticing and responding when nodes, containers or endpoints goes down. The controllers makes decisions to bring up new containers in such cases.<click> <click>The scheduler is responsible for distributing work or containers across multiple nodes.  It looks for newly created containers and assigns them to Nodes. 34Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nCluster\\nkube-apiserveretcdcontroller-managerkube-schedulerkubeletkubeletkubeletcontainer runtimecontainer runtimecontainer runtimekube-proxykube-proxykube-proxy\\nControlPlaneWorkerWorkerWorker\\nDockerkube-apiserveretcdcontroller-managerkube-scheduler', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 35}),\n",
              " Document(page_content=\"<click><click>On the worker nodes you have the kubeletwhich is the agent that runs on each node in the cluster. The agent is responsible for making sure that the containers are running on the nodes as expected.You also have the kube-proxy that is responsible for maintaining rules on the nodes.On the worker nodes you also have container runtime that is responsible for running containers. And one example of that is Docker. Now, it used to be Docker for a long time in the past –because Kubernetes was originally built to orchestrate Docker containers specifically. However over a period of time it evolved to support other container runtimes. So it no longer supports Docker directly, but supports the runtime component of Docker which today is managed by ContainerD. There is a separate video that talks about the whole history of Kubernetes and Docker and how they started out together and what changed.  So check it out in the link given below.So going forward we are going to refer to container runtime in kubernetesas containerD.And that's the high level architecture of a kubernetescluster. And next we will look into the kubernetesCLI.31/03/23\\n34\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 36}),\n",
              " Document(page_content=\"Let's take a look at the Kubectlutility. Kubectlis the command line utility of Kubernetes. This is the tool or command you would use to operate the kubernetescluster such as to view the status of the cluster, to provision application, to scale up, scale down, delete and many other things.\\n35Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudkubectl\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 37}),\n",
              " Document(page_content='One of the questions I get asked often is how to pronounce this. Different people pronounce it differently. Some say kubeC T L, other\\'s say kubecontrol, some say kubecuttle or kubecuddle. The canonical pronounciationis \"cube control\" though. So I\\'ll try to stick to that. I myself have changed the way I pronounce it over the years. KubeCuttle came easy to me so you\\'ll hear me say that at times.  Forgive me if you hear me mix it up at different times. Now that it is out of the way let\\'s get started. \\n36Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHow is it pronounced?cube C T Lcube controlcube cuttlecube cuddle', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 38}),\n",
              " Document(page_content='To identify the version of the kubectlclient and the kubernetesserver, run the kubectlversion command. This lists the client and server version along with the version of any other tool installed in the system. \\n37Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectlversionkubectlClient Version: v1.26.0+k3s1Server Version: v1.26.0+k3s1', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 39}),\n",
              " Document(page_content='Thehelpoption lists basic help information such as the basic commands that can be run. We will dig into these commands later in this video. \\n38Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectl--helpkubectlkubectlcontrols the Kubernetes cluster manager.Find more information at: https://kubernetes.io/docs/reference/kubectl/Basic Commands (Beginner):create          Create a resource from a file or from stdinexpose          Take a replication controller, service, deployment or pod and expose it as a new Kubernetes servicerun             Run a particular image on the clusterset             Set specific features on objectsBasic Commands (Intermediate):explain         Get documentation for a resourceget             Display one or many resourcesedit            Edit a resource on the serverdelete          Delete resources by file names, stdin, resources and names, or by resources and label selector', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 40}),\n",
              " Document(page_content=\"Let's begin with a few simple commands. To see a list of nodes in your cluster run the kubectlget nodes command. The output shows you the name of the node, it's status, the roles, how long the machine has been up and the version of Kubernetes running on that system.\\n39Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_\\n$kubectlget nodeskubectlNAME           STATUS   ROLES                  AGE   VERSIONcontrolplaneReady    control-plane,master10m   v1.26.0+k3s1worker1        Ready    worker                 10m   v1.26.0+k3s1worker2        Ready    worker                 10m   v1.26.0+k3s1\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 41}),\n",
              " Document(page_content='To get a more verbose output with more details such as internal IP, OSImage, kernel version, container runCme etc, run the same command with the –o wide opCon. \\n40Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_\\n$kubectlget nodeskubectl\\nNAME           STATUS   ROLES                  AGE   VERSION        INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIMEcontrolplaneReady    control-plane,master11m   v1.26.0+k3s1   172.25.0.6    <none>        Alpine Linux v3.16   5.4.0-1100-gcp   containerd://1.6.12-k3s1 worker1        Ready    worker                 10m   v1.26.0+k3s1   172.25.0.7    <none>        Alpine Linux v3.16   5.4.0-1100-gcp   containerd://1.6.12-k3s1 worker2        Ready    worker                 10m   v1.26.0+k3s1   172.25.0.8    <none>        Alpine Linux v3.16   5.4.0-1100-gcp   containerd://1.6.12-k3s1', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 42}),\n",
              " Document(page_content='It\\'s time for our first hands-on labs activity. Use the link given here to access the labs. As mentioned before the labs come free of cost with the course. All you need to do is signup for the free course and start the lab named \"Familiarize with the Lab environment\". In this lab you will use the kubectlcommands to identify the cluster setup and the nodes available in it. https://kodekloud.com/topic/labs-familiarize-with-lab-environment/\\n41Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHands-On Labs -Familiarize with the Lab environmenthttps://kode.wiki/kubernetes-labs\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 43}),\n",
              " Document(page_content=\"This course is designed for you to have a seamless experience from start to finish. And that's why we have labs after each concept that will help you gain hands-on experience on exactly what you learned until then.  So we are going to work on an existing Kubernetes cluster that's already setup and get familiarized with the cluster, the kubrnetescommand line interface, deploy applications to the cluster with pods, deployments, services etc. At the end of this course we'll share instructions on setting up your own local environment for you to continue your studies. Meanwhile we do not want you to be distracted with any issues that might come up when you try to build your own cluster. So my recommendation is to aim to complete this course with our labs and go from start to finish without any interruption. If this is a 3 hours course, you should aim to complete it in 3 hours or max 5 hours from now. So head over to the labs using the links given below and come back here one you are done.\\n42Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud[headshot video]\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 44}),\n",
              " Document(page_content=\"Let's take a look at Kubernetes Pods now. But before we begin, we would like to assume that the following have been setup already. \\n43Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudPods\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 45}),\n",
              " Document(page_content='At this point, we assume that the application is already developed and built into Docker Images and it is available on a Docker repository like Docker hub, so kubernetescan pull it down. We also assume that the Kubernetes cluster has already been setup and is working. \\n44Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudDocker Hub\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 46}),\n",
              " Document(page_content='As we discussed before, <click> with kubernetesour ultimate aim is to deploy our application in the form of containers on a set of machines that are configured as worker nodes in a cluster. <click> However, kubernetesdoes not deploy containers directly on the worker nodes.  The containers are encapsulated into a Kubernetes object known as PODs. A POD is a single instance of an application. A POD is the smallest object, that you can create in kubernetes.  So what happens when you want to scale up? \\n45Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 47}),\n",
              " Document(page_content='Do you add more containers to the same pod? No! You create more pods. Typically an application instance running as a container has a 1-to-1 relationship with a Pod. To create more instances of application you create more Pods. However the 1-to-1 relationship is not a strict rule. \\n46Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\npod', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 48}),\n",
              " Document(page_content=\"It is a common practice to have a helper container or a sidecar container along with the main application. Such as an agent that collects logs or monitors the application and reports to a third party. And that's absolutely fine. \\n47Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\npod\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 49}),\n",
              " Document(page_content='Let us now look at how to create PODs. <click> For this we run the kubectlrun command. We specify a name for the pod and the image to be used to create the pod. What this command really does is it deploys a container by creating a POD. So it first creates a POD automatically and deploys an instance of the nginx docker image. <click> But were does it get the application image from? <click> For that you need to specify the image name using the –-image parameter. The application image, in this case the nginx image, is downloaded from the docker hub repository. Docker hub as we discussed is a public repository were latest docker images of various applications are stored. You could configure kubernetesto pull the image from the public docker hub or a private repository within the organization. Now that we have a POD created, how do we see the list of PODs available? <click> The kubectlget PODs command helps us see the list of pods in our cluster. In this case we see the pod is in a ContainerCreatingstate and soon changes to a Running state when it is actually running.Also remember that we haven’t really talked about the concepts on how a user can access the nginx web server. And so in the current state we haven’t made the web server accessible to external users. You can access it internally from the Node though. 48Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_\\n$kubectlrun nginxpod/nginx created$kubectlget podsNAME    READY   STATUS              RESTARTS   AGEnginx   1/1     ContainerCreating0          5m50s\\nDocker Hub\\nNAME    READY   STATUS    RESTARTS   AGEnginx   1/1     Running   0          5m50s--image=nginx', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 50}),\n",
              " Document(page_content='<click>  For now we will just see how to deploy a POD and in a later lecture once we learn about networking and services we will get to know how to make this service accessible to end users.Now this is called as the imperative way to create a POD. Let us now see the declarative way to create a POD. 31/03/23\\n48', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 51}),\n",
              " Document(page_content='So that was the imperative way of creating an object in Kubernetes. You run a command to create one object at a time. When there are many objects and services in your application this is not a viable option.The more preferred approach is the declarative way, where you create a YAML file with the specifications of the object –the pod in this case. And have kubernetesapply that configuration. This way you can define the state of your application and its services as code and store it in source code repositories and version them. This approach enables version control, CI/CD and sharing these with others and collaborating together. \\n49Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_Imperative vs Declarative$kubectlrun nginxpod/nginx createdapiVersion: kind:pod-definition.ymlv1Podmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage: nginx', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 52}),\n",
              " Document(page_content=\"If you are new to YAML check out our free course on YAML and JSON available on KodeKloud. There are hands-on activities that can help you get very comfortable with YAML soon. Because it's going to be an important necessity going forward.\\n50Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud[YAML & JSON Course Demo]\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 53}),\n",
              " Document(page_content='Now we will learn how to develop YAML files specifically for Kubernetes. Kubernetes uses YAML files as input for the creation of objects such as PODs, Replicas, Deployments, Services etc. All of these follow similar structure. A kubernetesdefinition file always contains 4 top level fields. <click> The apiVersion, kind, metadata and spec. These are top level or root level properties. Think of them as siblings, children of the same parent. These are all REQUIRED fields, so you MUST have them in your configuration file. Let us look at each one of them. The first one is the apiVersion. This is the version of the kubernetesAPI we’re using to create the object.  Depending on what we are trying to create we must use the RIGHT apiVersion. For now since we are working on PODs, <click 2> we will set the apiVersionas v1. If you are creating a service, replicasetor deployments you will use the versions listed here. We will see what these are later in this course.Next is the kind. The kind refers to the type of object we are trying to create, which in this case happens to be a POD. So we will set it as <c> Pod. Some other possible values here could be ReplicaSetor Deployment or Service, which is what you see in the kind field in the table on the right.51Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectlcreate –f pod-definition.ymlapiVersion: kind:metadata:spec:pod-definition.ymlv1Podname: myapp-podlabels:app: myapptype: front-endcontainers:-name: nginx-containerimage: nginxStringStringDictionary\\nKindVersionPodv1Servicev1ReplicaSetapps/v1Deploymentapps/v1metadata:name: myapp-pod\\nlabels:app: myapp\\nList/Array1stItem in List', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 54}),\n",
              " Document(page_content='The next is metadata. <click> The metadata is data about the object like its name, labels etc.  <click> As you can see unlike the first two were you specified a string value, this, is in the form of a dictionary. <click> So everything under metadata is intended to the right a little bit and so names and labels are children of metadata.  <click> The number of spaces before the two properties name and labels doesn’t matter, <click> but they should be the same as they are siblings. In this case labels has more spaces on the left than name and so it is now a child of the name property instead of a sibling. <click> Also the two properties must have MORE spaces than its parent, which is metadata, so that its intended to the right a little bit. In this case all 3 have the same number of spaces before them and so they are all siblings, which is not correct. <click> Under metadata, the name is a string value –so you can name your POD myapp-pod -and the labels is a dictionary.  So labels is a dictionary within the metadata dictionary. And it can have any key and value pairs as you wish. For now I have added a label app with the value myapp. Similarly you could add other labels as you see fit which will help you identify these objects at a later point in time. Say for example there are 100s of PODs running a front-end application, and 100’s of them running a backend application or a database, it will be DIFFICULT for you to group these PODs once they are deployed. If you label them now as front-end, back-end or database, you will be able to filter the PODs based on this label at a later point in time. It’s IMPORTANT to note that under metadata, you can only specify name or labels or anything else that kubernetesexpects to be under metadata. You CANNOT add any other property as you wish under this. However, under labels you CAN have any kind of key or value pairs as you see fit. So its IMPORTANT to understand what each of these parameters expect.  So far we have only mentioned the type and name of the object we need to create which happens to be a POD with the name myapp-pod, but we haven’t really specified the container or image we need in the pod. The last section in the configuration file is the specification which is written as spec. Depending on the object we are going to create, this is were we provide additional information to kubernetespertaining to that object. This is going to be different for different objects, so its important to understand or refer to the documentation section to get the right format for each. Since we are only creating a pod with a single container in it, it is easy. Spec is a dictionary so add a property under it called containers, <click> which is a list or an array. The reason this property is a list is because the PODs can have multiple containers within them as we learned in the lecture earlier. In this case though, we will only add a single item in the list, <click> since we plan to have only a single container in the POD. The item in the list is a dictionary, so add a name and image property. The value for image is nginx.  <click>31/03/23\\n51', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 55}),\n",
              " Document(page_content='<click>Once the file is created, run the command kubectlcreate -f followed by the file name which is pod-definition.ymland kubernetescreates the pod.So to summarize remember the 4 top level properties. apiVersion, kind, metadata and spec. Then start by adding values to those depending on the object you are creating. 31/03/23\\n51', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 56}),\n",
              " Document(page_content='Once we create the pod, how do you see it? Use the <click> kubectlget pods command to see a list of pods available. In this case its just one. To see detailed information about the pod run the <click> kubectldescribe pod command.  This will tell you information about the POD, when it was created, what labels are assigned to it, what docker containers are part of it and the events associated with that POD. \\n52Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectlget podsNAME             READY     STATUS    RESTARTS   AGEmyapp-pod        1/1       Running   0          20s$kubectldescribe pod myapp-podName:         myapp-podNamespace:    defaultNode:         minikube/192.168.99.100Start Time:   Sat, 03 Mar 2018 14:26:14 +0800Labels:       app=myappname=myapp-podAnnotations:  <none>Status:       RunningIP:           10.244.0.24Containers:nginx:Container ID:   docker://830bb56c8c42a86b4bb70e9c1488fae1bc38663e4918b6c2f5a783e7688b8c9dImage:          nginxState:          RunningStarted:      Sat, 03 Mar 2018 14:26:21 +0800Ready:          TrueRestart Count:  0Environment:    <none>Mounts:/var/run/secrets/kubernetes.io/serviceaccountfrom default-token-x95w7 (ro)Conditions:Type           StatusInitialized    TrueReady          TruePodScheduledTrueEvents:Type    Reason                 Age   From               Message-------------------------Normal  Scheduled              34s   default-scheduler  Successfully assigned myapp-pod to minikubeNormal  SuccessfulMountVolume33s   kubelet, minikubeMountVolume.SetUpsucceeded for volume \"default-token-x95w7\"Normal  Pulling                33s   kubelet, minikubepulling image \"nginx\"Normal  Pulled                 27s   kubelet, minikubeSuccessfully pulled image \"nginx\"Normal  Created                27s   kubelet, minikubeCreated containerNormal  Started                27s   kubelet, minikubeStarted container', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 57}),\n",
              " Document(page_content=\"It's time for our second hands-on labs activity. Go back to the labs and access the labs for PODs. Or click on the link given here. In this lab you will create pods and also explore creating YAML files for PODs. Once done come back here and we will resume the course.https://kodekloud.com/topic/labs-pods-with-yaml/\\n53Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHands-On Labs -PODshttps://kode.wiki/kubernetes-labs\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 58}),\n",
              " Document(page_content=\"Let's now talk about ReplicaSets\\n54Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudReplicaSets\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 59}),\n",
              " Document(page_content='So what is a replica and why do we need a replicaset? <click> Let’s go back to our ﬁrst scenario were we had a single POD running our applicaCon. <click> What if for some reason, our applicaCon crashes and the POD fails? Users will no longer be able to access our applicaCon. \\n55Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 60}),\n",
              " Document(page_content='To prevent users from losing access to our application, we would like to have more than one instance or POD running at the same time. That way if one fails we still have our application running on the other one. And the replicasetbrings the failed one back to ensure a pre-defined number of replicas are always running <click> The replicasethelps us run multiple instances of a single POD in the kubernetescluster thus providing <click> High Availability. So does that mean you can’t use a replicasetif you plan to have a single POD? No! Even if you have a single POD, <click> the replication controller can help by automatically bringing up a new POD when the existing one fails. Thus the replicasetensures that the specified number of PODs are running at all times. Even if it’s just 1 or 100.Another reason we need replicasetis to create multiple PODs to share the load across them.  For example, <click> in this simple scenario we have a single POD serving a set of users. <click> When the number of users increase and If we were to run out of resources on the first node, \\n56Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npodpodreplicaset\\npod\\npodreplicaset\\npod', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 61}),\n",
              " Document(page_content='we could deploy additional PODs across other nodes in the cluster. As you can see, the replicasetspans across multiple nodes in the cluster. It helps us balance the load across multiple pods on different nodes as well as scale our application when the demand increases.So a Pod has a one-to-one relationship with a node. A pod can only run on one node. You cannot move a pod from one node to the other. . A replicasetspans across the entire cluster. \\n57Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npodpodreplicaset\\npod\\npodreplicaset', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 62}),\n",
              " Document(page_content=\"So a Pod has a one-to-one relationship with a node. A pod can only run on one node at a time. You cannot move a pod from one node to the other. You'll have to kill it and recreate it on another node. Well, technically the scheduler decides which node a pod gets assigned to and there are ways for you to control that which is out of scope for this crash course. We discuss those in much detail in our CKA course. For now we will just stick to the basics. So a pod lives on one node.A replicaset,  spans across the entire cluster. And a replicasetcan deploy a pod on any node in the cluster. It monitors the number of pods in the cluster and ensures enough is deployed at all times.\\n58Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npodpodreplicaset\\npod\\npod\\nreplicaset\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 63}),\n",
              " Document(page_content='Let us now look at how we create a replicaset. <click> As with the previous lecture, we start by creating a replicasetdefinitionfile. We will name it replicaset-definition.yml. As with any kubernetesdefinition file, we will have 4 sections. The apiVersion, kind, metadata and spec. The apiVersionis specific to what we are creating. In this case replicasetis supported in kubernetesapiVersionapps/v1.. <click> If you get this wrong, you are likely to get an error that looks like this. It would say no match for kind ReplicaSet, because the specified kubernetesapiversion has no support for ReplicaSet. <click> The kind as we know is ReplicaSet. Under metadata, we will add a name and we will call it myapp-replicaset. And we will also add a few labels, app and type and assign values to them. So far, it has been very similar to how we created a POD in the previous section. The next is the most crucial part of the definition file and that is the specification written as spec. For any kubernetesdefinition file, the spec section defines what’s inside the object we are creating. In this case we know that the replicasetcreates multiple instances of a POD. But what POD? <click> We create a template section under spec to provide a POD template to be used by the replicasetto create replicas. Now <pause> how do we DEFINE the POD template? It’s not that hard because, we have already done that in the previous exercise. <click> Remember, 59Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudapiVersion: kind:metadata:spec:replicaset-definition.ymlapps/v1ReplicaSetname: myapp-replicasetlabels:app: myapptype: front-end\\n$kubectlcreate –f replicaset-definition.ymlapiVersion: kind:pod-definition.ymlv1Podtemplate:PODmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage: nginxPODreplicas:\\n3selector:\\nmatchLabels:type:front-endreplicaset\"myapp-replicaset\" created$kubectlget replicasetNAME       DESIRED   CURRENT    READY       AGEmyapp-replicaset3         3         3         19s$kubectlget podsNAME                    READY      STATUS    RESTARTS   AGEmyapp-replicaset-9ddl9   1/1       Running   0          45smyapp-replicaset-9jtpx   1/1       Running   0          45smyapp-replicaset-hq84m   1/1       Running   0          45s\\nerror: unable to recognize \"replicaset-definition.yml\": no matches for /, Kind=ReplicaSet', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 64}),\n",
              " Document(page_content='we created a pod-definition file in the previous exercise. We could re-use the contents of the same file to populate the template section. <click> Move all the contents of the pod-definition file into the template section of the replication controller, except for the first two lines –which are apiVersionand kind. <click> Remember whatever we move must be UNDER the template section. Meaning, they should be intended to the right and have more spaces before them than the template line itself. <click> Looking at our file, we now have two metadata sections –one is for the ReplicaSetand another for the POD and <click> we have two spec sections –one for each. We have nested two definition files together. The replication controller being the parent and the pod-definition being the child. <click> Now, there is something still missing. <click> We haven’t mentioned how many replicas we need in the replication controller. For that, <click> add another property to the spec called replicas and <click>  input the number of replicas you need under it. Remember that the template and replicas are direct children of the spec section. So they are siblings and must be on the same vertical line : having equal number of spaces before them.Replica set requires a selector definition.  The selector section helps the replicasetidentify what pods fall under it. But why would you have to specify what PODs fall under it, if you have provided the contents of the pod-definition file itself in the template? It’s BECAUSE, replica set can ALSO manage pods that were not created as part of the replicasetcreation. Say for example, there were pods created BEFORE the creation of the ReplicaSetthat match the labels specified in the selector, the replica set will also take THOSE pods into consideration when creating the replicas. I will elaborate this in the next slide. For now know that it has to be written in the form of matchLabelsas shown here. The matchLabelsselector simply matches the labels specified under it to the labels on the PODs. The replicasetselector also provides many other options for matching labels that were not available in a replication controller.Once the file is ready, <click> run the kubectlcreate command and input the file using the –f parameter. The replicasetIs created. When the replicasetis created it first creates the PODs using the pod-definition template as many as required, which is 3 in this case. To view the list of created replicaset<click> run the kubectlget replicasetcommand and you will see the replicasetlisted. We can also see the desired number of replicas or pods, the current number of replicas and how many of them are ready. If you would like to see the pods that were created by the replicaset, run the <click> kubectlget pods command and you will see 3 pods running. Note that all of them are starting with the name of the replicasetwhich is myapp-replicasetindicating that they are all created automatically by the replicaset.31/03/23\\n59', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 65}),\n",
              " Document(page_content='So what is the deal with Labels and Selectors? Why do we label our PODs and objects in kubernetes? Let us look at a simple scenario. <click> Say we deployed 3 instances of our frontend web application as 3 PODs. <click> We would like to create a replication controller or replica set to ensure that we have 3 active PODs at anytime. And YES that is one of the use cases of replica sets. You CAN use it to monitor existing pods, if you have them already created, as it IS in this example. In case they were not created, the replica set will create them for you. The role of the replicasetis to monitor the pods and if any of them were to fail, deploy new ones. The replica set is in FACT a process that monitors the pods. Now, how does the replicasetKNOW what pods to monitor. <click> There could be 100s of other PODs in the cluster running different application. <click> This is were labelling our PODs during creation comes in handy. <click> We could now provide these labels as a filter for replicaset. Under the selector section we use the matchLabelsfilter and provide the same label that we used while creating the pods. This way the replicasetknows which pods to monitor.\\n60Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nmetadata:name: myapp-podlabels:tier: front-endpod-definition.ymlselector:matchLabels:tier:front-endreplicaset-definition.yml', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 66}),\n",
              " Document(page_content='Now let me ask you a question along the same lines. In the replicasetspecification section we learned that there are 3 sections: Template, replicas and the selector. <click> We need 3 replicas and we have updated our selector based on our discussion in the previous slide. Say for instance we have the same scenario as in the previous slide were we have 3 existing PODs that were created already and we need to create a replica set to monitor the PODs to ensure there are a minimum of 3 running at all times. When the replication controller is created, it is NOT going to deploy a new instance of POD as 3 of them with matching labels are already created.  <click> In that case, do we really need to provide a template section in the replica-set specification, since we are not expecting the replicasetto create a new POD on deployment? Yes we do, BECAUSE in case one of the PODs were to fail in the future, the replicasetneeds to create a new one to maintain the desired number of PODs. And for the replica set to create a new POD, the template definition section IS required.\\n61Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudapiVersion: kind:metadata:spec:replicaset-definition.ymlReplicaSetname: myapp-replicasetlabels:app: myapptype: front-endapps/v1\\nmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage: nginxreplicas:selector:matchLabels:type:front-endtemplate:\\n3\\ntier: front-end\\ntier: front-end\\ntier: front-endTemplate\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 67}),\n",
              " Document(page_content='Let’s look at how we scale the replicaset. Say we started with 3 replicas and in the future we decide to scale to 6. How do we update our replicasetto scale to 6 replicas. Well there are multiple ways to do it. The first, is to update the number of replicas in the definition file to <click> 6. Then <click> run the kubectlreplace command specifying the same file using the –f parameter and that will update the replicasetto have 6 replicas.  The second way to do it is to run the <click> kubectlscale command.  Use the replicas parameter to provide the new number of replicas and specify the same file as input. <click> You may either input the definition file or provide the replicasetname in the TYPE Name format. However, Remember that using the file name as input will not result in the number of replicas being updated automatically in the file.  In otherwords, the number of replicas in the replicaset-definition file will still be 3  even though you scaled your replicasetto have 6 replicas using the kubectlscale command and the file as input.There are also options available for automatically scaling the replicasetbased on load, but that is an advanced topic and we will discuss it at a later time.62Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_apiVersion: kind:metadata:spec:replicaset-definition.ymlReplicaSetname: myapp-replicasetlabels:app: myapptype: front-endapps/v1\\nmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage: nginxreplicas:selector:matchLabels:type:front-endtemplate:\\n3$kubectlreplace -f replicaset-definition.yml\\n6$kubectlscale -–replicas=6 –f replicaset-definition.yml$kubectlscale -–replicas=6 replicasetmyapp-replicasetTYPE        NAME', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 68}),\n",
              " Document(page_content='Let us now review the commands real quick. <click> The kubectlcreate command, as we know, is used to create a replcaset. You must provide the input file using the –f parameter. <click> Use the kubectlget command to see list of replicasetscreated. <click> Use the kubectldelete replicasetcommand followed by the name of the replica set to delete the replicaset. <click> And then we have the kubectlreplace command to replace or update replicasetand also the <click> kubectlscale command to scale the replicas simply from the command line without having to modify the file.\\n63Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectlcreate –f replicaset-definition.yml$kubectlget replicaset$kubectldelete replicasetmyapp-replicaset$kubectlreplace -f replicaset-definition.yml$kubectlscale –replicas=6 -f replicaset-definition.yml', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 69}),\n",
              " Document(page_content=\"It's time for labs activity. Click on the link to go directly to the labs. If you haven't enrolled already enroll for free. https://kodekloud.com/topic/labs-pods-with-yaml/\\n64Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHands-On Labs -ReplicaSethttps://kode.wiki/kubernetes-labs\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 70}),\n",
              " Document(page_content=\"Let's now talk about Deployments. \\n65Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudDeployment\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 71}),\n",
              " Document(page_content=\"So we saw how to deploy an application to Kubernetes by creating a pod and deploying multiple instances using replicasets. But deploying and managing the number of replicas won't cut it when it comes to deploying applications for production use cases. <click> when newer versions of application is released, you would like to UPGRADE your application instances seamlessly. when you upgrade your instances, you may want to upgrade them one after the other. And that kind of upgrade is known as Rolling Updates.Suppose one of the upgrades you performed resulted in an unexpected error and you are asked to undo the recent update. You would like to be able to <click> rollBACKthe changes that were recently carried out.Finally, say for example you would like to make multiple changes to your environment such as upgrading the underlying WebServerversions, as well as scaling your environment and also modifying the resource allocations etc. You do not want each change to be applied immediately after the command is run, instead you would like 66Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npodreplicaset\\npod\\npod\\npod\\npod\\ndeploymentDeployment\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 72}),\n",
              " Document(page_content='to apply a <click> pause to your environment, make the changes and then resume <click> so that all changes are rolled-out together.<click> All of these capabilities are available with the kubernetesDeployments. <click> So far in this course we discussed about PODs, which deploy single instances of our application such as the web application in this case. Each container is encapsulated in PODs. <click> Multiple such PODs are deployed using Replica Sets.  <click> And then comes Deployment which is a kubernetesobject that comes higher in the hierarchy. The deployment provides us with capabilities to upgrade the underlying instances seamlessly using rolling updates, undo changes, and pause and resume changes to applications running on the cluster.31/03/23\\n66', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 73}),\n",
              " Document(page_content='So how do we create a deployment. <click> As with the previous components, we ﬁrst create a deployment deﬁniCon ﬁle.  The contents of the deployment-deﬁniCon ﬁle are exactly similar to the replicasetdeﬁniCon ﬁle, except for the kind, which is now going to be Deployment.If we walk through the contents of the ﬁle it has an apiVersionwhich is apps/v1, metadata which has name and labels and a spec that has template, replicas and selector. The template has a POD deﬁniCon inside it. <click> Once the ﬁle is ready run the kubectlcreate command and specify deployment deﬁniCon ﬁle. <click> Then run the kubectlget deployments command to see the newly created deployment.  The deployment automaCcally creates a replica set. <click> So if you run the kubectlget replcasetcommand you will be able to see a new replicasetin the name of the deployment. <click> The replicasetsulCmately create pods, so if you run the kubectlget pods command you will be able to see the pods with the name of the deployment and the replicaset.So far there hasn’t been much of a diﬀerence between replicasetand deployments, except for the fact that deployments created a new kubernetesobject called 67Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_apiVersion: kind:metadata:spec:deployment-definition.ymlReplicaSetname: myapp-deploymentlabels:app: myapptype: front-endapps/v1\\nmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage: nginxreplicas:selector:matchLabels:type:front-endtemplate:\\n3Deployment$kubectlcreate –f deployment-definition.ymldeployment \"myapp-deployment\" created$kubectlget deploymentsNAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGEmyapp-deployment   3         3         3            3           21s$kubectlget replicasetNAME                          DESIRED   CURRENT   READY     AGEmyapp-deployment-6795844b58   3         3         3         2m$kubectlget podsNAME                                READY     STATUS    RESTARTS   AGEmyapp-deployment-6795844b58-5rbjl   1/1       Running   0          2mmyapp-deployment-6795844b58-h4w55   1/1       Running   0          2mmyapp-deployment-6795844b58-lfjhv   1/1       Running   0          2m', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 74}),\n",
              " Document(page_content='deployments. We will see how to take advantage of the deployment using the use cases we discussed in the previous slide in the upcoming lectures.31/03/23\\n67', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 75}),\n",
              " Document(page_content='To see all the created objects at once run the kubectlget all command.\\n68Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_$kubectlget allNAME                      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGEdeploy/myapp-deployment   3         3         3            3           9hNAME                             DESIRED   CURRENT   READY     AGErs/myapp-deployment-6795844b58   3         3         3         9hNAME                                   READY     STATUS    RESTARTS   AGEpo/myapp-deployment-6795844b58-5rbjl   1/1       Running   0          9hpo/myapp-deployment-6795844b58-h4w55   1/1       Running   0          9hpo/myapp-deployment-6795844b58-lfjhv   1/1       Running   0          9h', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 76}),\n",
              " Document(page_content='Now once a deployment is created and you have a newer version of the app available, how do you upgrade your application? As before one way is to updated the deployment definition file to update the new image name with the newer version of the app. The imperative approach would be to use the kubectlset image command and specify the deployment name and the image name like this. \\n69Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_apiVersion: kind:metadata:spec:deployment-definition.ymlname: myapp-deploymentlabels:app: myapptype: front-endapps/v1\\nmetadata:name: myapp-podlabels:app: myapptype: front-endspec:containers:-name: nginx-containerimage:replicas:selector:matchLabels:type:front-endtemplate:\\n3Deployment$kubectlapply –f deployment-definition.ymldeployment \"myapp-deployment\" configured$kubectlset image deployment/myapp-deployment \\\\nginx-container=nginx:1.9.1deployment \"myapp-deployment\" is updatednginxnginx:1.7.1', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 77}),\n",
              " Document(page_content=\"It's time for labs activity. Click on the link to go directly to the labs. If you haven't enrolled already enroll for free.  In this lab you will work on creating deployments and deploying applications to a kubernetescluster. https://kodekloud.com/topic/labs-pods-with-yaml/\\n71Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHands-On Labs -Deploymentshttps://kode.wiki/kubernetes-labs\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 78}),\n",
              " Document(page_content='72Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudUpdates and Rollback', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 79}),\n",
              " Document(page_content='73Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 80}),\n",
              " Document(page_content='Let us now talk about Networking 101 with Kubernetes. \\n74Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudKubernetes Networking 101', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 81}),\n",
              " Document(page_content='Let us look at the very basics of networking in Kubernetes. <click> We will start with a single node kubernetescluster. The node has an IP address, say it is 192.168.1.2 in this case. This is the IP address we use to access the kubernetesnode, SSH into it etc. So on the single node kubernetescluster we have created a Single POD.  As you know a POD hosts a container.  Unlike in the docker world were an IP address is always assigned to a Docker CONTAINER, <click>in Kubernetes the IP address is assigned to a POD. Each POD in kubernetesgets its own internal IP Address. In this case its in the range 10.244 series and the IP assigned to the POD is 10.244.0.2. So how is it getting this IP address? When Kubernetes is initially configured it creates an internal private network with the address 10.244.0.0 <click>and all PODs are attached to it. <click> When you deploy multiple PODs, they all get a separate IP assigned. The PODs can communicate to each other through this IP . But accessing other PODs using this internal IP address MAY not be a good idea as its subject to change when PODs are recreated. We will see BETTER ways to establish communication between PODs in a while. For now its important to understand how the internal networking works in kubernetes.75Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n192.168.1.210.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0Node1', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 82}),\n",
              " Document(page_content='So it’s all easy and simple to understand when it comes to networking on a single node. But how does it work when you have multiple nodes in a cluster? In this case we have two nodes running kubernetesand they have IP addresses 192.168.1.2 and 192.168.1.3 assigned to them. Note that they are not part of the same cluster yet. <click> Each of them has a single POD deployed. As discussed in the previous slide these pods are attached to an internal network and they have their own IP addresses assigned. HOWEVER, if you look at the network addresses, <click> you can see that they are the same. The two networks have an address 10.244.0.0 and the PODs deployed have the same address too. <click> This is NOT going to work well when the nodes are part of the same cluster. The PODs have the same IP addresses assigned to them and that will lead to IP conflicts in the network. Now that’s ONE problem. When a kubernetescluster is SETUP , kubernetesdoes NOT automatically setup any kind of networking to handle these issues. As a matter of fact, kubernetesexpects US to setup networking to meet certain fundamental requirements. Some of these are that <click> all the containers or PODs in a kubernetescluster MUST be able to communicate with one another without having to configure NAT. <click> All nodes must be able to communicate with containers and all containers must be able to communicate with the nodes in the 76Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n192.168.1.210.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0\\n192.168.1.3\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0Node1Node2\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 83}),\n",
              " Document(page_content='cluster. Kubernetes expects US to setup a networking solution that meets these criteria.  31/03/23\\n76', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 84}),\n",
              " Document(page_content='Some of these are that <click> all the containers or PODs in a kubernetescluster MUST be able to communicate with one another without having to configure NAT. <click> All nodes must be able to communicate with containers and all containers must be able to communicate with the nodes in the cluster. Kubernetes expects US to setup a networking solution that meets these criteria.  \\n77Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n192.168.1.210.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0\\n192.168.1.3\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0Node1Node2\\n☝All containers/PODs can communicate to one another without NAT\\n☝All nodes can communicate with all containers and vice-versa without NAT', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 85}),\n",
              " Document(page_content='Fortunately, we don’t have to set it up ALL on our own as there are multiple pre-built solutions available. Some of them are the cisco ACI networks, Cilium, Big Cloud Fabric, Flannel, VmwareNSX-t and Calico. Depending on the platform you are deploying your Kubernetes cluster on you may use any of these solutions. For example, if you were setting up a kubernetescluster from scratch on your own systems, you may use any of these solutions like Calico, Flannel etc. If you were deploying on a Vmwareenvironment NSX-T may be a good option. If you look at the play-with-k8s labs they use WeaveNet. In our demos in the course we used Calico. Depending on your environment and after evaluating the Pros and Cons of each of these, you may chose the right networking solution.\\n78Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 86}),\n",
              " Document(page_content='The step to install a pod network add-on is part of the kubernetescluster creation process. \\n79Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 87}),\n",
              " Document(page_content='So back to our cluster, with the <click> Calico networking setup,\\n80Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n192.168.1.210.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0\\n192.168.1.3\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.410.244.0.0Node1Node2', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 88}),\n",
              " Document(page_content='it now manages the networks and Ips in my nodes and assigns a different network address for each network in the nodes. This creates a virtual network of all PODs and nodes were they are all assigned a unique IP Address. And by using simple routing techniques the cluster networking enables communication between the different PODs or Nodes to meet the networking requirements of kubernetes. Thus all PODs can now communicate to each other using the assigned IP addresses.\\n81Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod\\n192.168.1.2\\npod\\npod\\n192.168.1.3\\npod\\npod\\npodNode1Node2\\nCalicoRouting\\n10.244.0.210.244.0.310.244.0.410.244.0.010.244.2.210.244.2.310.244.2.410.244.2.0', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 89}),\n",
              " Document(page_content='82Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudServices', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 90}),\n",
              " Document(page_content='So we have two sets of services deployed in our application. A webserver and a redisservice. Kubernetes assigns a unique IP address to each pod in the cluster.  The webserver has 10.244.0.2 and the pod has 10.244.0.11The web server needs to access the redisservice. \\n83Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\n10.244.0.11\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 91}),\n",
              " Document(page_content=\"So what would the webserver address the redisdeployment as? The redispod has an IP address. Can the webserver address the redisservice using it's IP address? It can, but It shouldn't because the IP is for each POD and it is bound to change if the pod where to crash or restart for some reason. That's where a service comes in. A service enables communication between applications within a kubernetescluster.  Think of a service as a proxy or a load balancer –although it technically is not  in a traditional sense. And it provides an endpoint for other services to connect to. In this case we create a service named redis-dband now the web application can refer tot his service with the name redis-db. \\n84Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\n10.244.0.11\\n????????\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 92}),\n",
              " Document(page_content=\"Similarly to expose the webservice outside to the external users you would create another service for the web server. We will call it the web-service. So a service enables connectivity between applications within the cluster as well as to expose applications outside the cluster to end users. We'll see how to create service in a few minutes, but first let's understand the different kinds of services. \\n85Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\n10.244.0.11\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 93}),\n",
              " Document(page_content='The first one we discussed is the clusteripservice. This is a service within the cluster that is not exposed externally and helps different services communicate with each other. This is the example we saw about the web server reaching the redisservice. the redisdbservice is a clusterIPtype of service. The second is NodePort–<click> and in this case the service exposes the application on a port on the Node to be made accessible to external users. <click> The third type is a LoadBalancer, were it provisions a load balancer for our service in supported cloud providers –like Google Cloud, AWS or Azure. A good example of that would be to distribute load across different web servers. In the scope of this course we will look at the ClusterIPand NodePortservices. \\n86Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudNodePortClusterIPLoadBalancer', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 94}),\n",
              " Document(page_content=\"Let's look at the ClusterIPtype of service.\\n87Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudClusterIP\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 95}),\n",
              " Document(page_content='The service we talked about earlier –where the web server tries to connect to the redisservice is the ClusterIPtyepof service. This is pretty straight forward.\\n88Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\n10.244.0.11\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 96}),\n",
              " Document(page_content=\"So here we have a redispod that needs to be exposed within the cluster for the web applicaCon. We do that by <c> creaCng a service. But we know that pods are usually deployed in replicas. <c> MulCple instances. <c> And there could 100s of other pods in the cluster. How can a service idenCfy which are the pods that it should be rouCng traﬃc to? Again same as before we have labels and selectors. The pods have a label with the name set to redis-pod. We deﬁne the same label as a selector on the service. <c> The service idenCﬁes all pods with the same label and conﬁgures them as it's endpoints. \\n89Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n10.244.0.11\\n10.244.0.11\\n10.244.0.11\\npod\\n10.244.0.2\\npod\\n10.244.0.2\\nname: redis-pod\\nname: redis-pod\\nname: redis-pod\\nname: redis-pod\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 97}),\n",
              " Document(page_content='To create such a service, as always, use a definition file. In the service definition file , first use the default template which has apiVersion, kind, metadata and spec. The apiVersionis v1 <click> , kind is Service and we will give a name to our service –we will call it redis-db. <click>  Under spec we have type and ports. The type is ClusterIP. In fact, ClusterIPis the default type, so even if you didn’t specify it, it will automatically assume it to be ClusterIP. Under ports we have a targetPortand port. The target port is the port were the back-end is exposed, which in this case is 6379. And the port is were the service is exposed. Which is 6379 as well. I\\'ll explain that in a bit more detail in a sec <click> To link the service to a set of PODs, we use selector. We will refer to the pod-definition file <click> and copy the labels from it and move it under selector.  And that should be it. <click> We can now create the service using the kubectlcreate command and then check its status using <click> the kubectlget services command. The service can be accessed by other PODs using the ClusterIPor the service name. Prefereblythe service name. \\n90Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudapiVersion: kind:metadata:spec:service-definition.ymlv1Servicename: redis-dbtype: ClusterIPports:-targetPort: 6379port: 6379selector:$ kubectlcreate –f service-definition.ymlservice “redis-db\" created$ kubectlget servicesNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGEkubernetes      ClusterIP10.96.0.1        <none>        443/TCP        16dredis-dbClusterIP10.106.127.123   <none>        80/TCP         2m\\npod10.244.0.2\\n10.244.0.11\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 98}),\n",
              " Document(page_content=\"So let's talk about ports. When creating a service we must specify what port the application running inside the pod is listening on. And that's defined as the target port here. We also need to specify which port the service must serve on. And these could be different. The applications could be listening on one port and the service could be listening on another. However in this case since any application connecting to redisexpects it to be at 6379 we are going to stick to the same port. So if you look at the code of the webserver, to connect to the redisservice it must use the name of the service as the host which in this case is redis-db. And use the same port defined as the port on the service. Which in this case is 6379.\\n91Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\n10.244.0.11\\n63796379apiVersion: kind:metadata:spec:service-definition.ymlv1Servicename: redis-dbtype: ClusterIPports:-targetPort: 6379port: 6379selector:app: myappname: redis-pod\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 99}),\n",
              " Document(page_content=\"Let's look at what a NodePortservice is. \\n92Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudNodePort\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 100}),\n",
              " Document(page_content='A nodeportis a type of service where a <c> normal service is created first. And is then exposed to external users through a port on the node. Let’s take a closer look at the Service. If you look at it, there are 3 ports involved. The port on the POD were the actual web server is running is port <click> 80. And it is referred to as the targetPort, because that is were the service forwards the requests to. The second port is the port on the <click> service itself. It is simply referred to as the port. Remember, these terms are from the viewpoint of the service. And finally we have the port on the Node itself <click> which we use to access the web server externally. And that is known as the NodePort.  As you can see it is 30008. That is because NodePortscan only be in a valid range which is from 30000 to 32767.\\n93Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\nNode808030008Range: 30000 -32767', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 101}),\n",
              " Document(page_content='Let us now look at how to create the service. As before we will use a definition file to create a service. The high level structure of the file remains the same. <click> we have apiVersion, kind, metadata and spec sections. <click> The apiVersionis going to be v1. <click> The kind is ofcourseservice. <click> The metadata will have a name and that will be the name of the service. It can have labels, but we don’t need that for now. Next we have spec. and as always this is the most crucial part of the file as this is were we will be defining the actual services and this is the part of a definition file that differs between different objects. <click> In the spec section of a service we have type and ports. The type refers to the type of service we are creating. As discussed before it could be ClusterIP, NodePort, or LoadBalancer. In this case since we are creating a NodePortwe will set it as NodePort. The next part of spec is ports. This is were we input information regarding what we discussed on the left side of this screen. The first type of port is the targetPort, <click> which we will set to 80. The next one is simply port, <click> which is the port on the service object and we will set that to 80 as well. The third is NodePort<click> which we will set to 30008 or any number in the valid range. Remember that out of these, the only mandatory field is port <click>. If you don’t provide a targetPortit is assumed to be the same as port and if you don’t provide a nodePorta free port in the valid range between 30000 and 32767 is automatically 94Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\nNode808030008apiVersion: kind:metadata:spec:service-definition.ymlv1Servicename: web-servicetype: NodePortports:-targetPort: 80port: 80nodePort: 30008*Range: 30000 -32767', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 102}),\n",
              " Document(page_content='allocated. Also note that ports is an array. So note the dash <click> under the ports secCon that indicate the ﬁrst element in the array. You can have mulCple such port mappings within a single service.So we have all the informaCon in, but something is really missing. There is nothing here in the deﬁniCon ﬁle that connects the service to the POD. We have simply speciﬁed the targetPortbut we didn’t menCon the targetPorton which POD. There could be 100s of other PODs with web services running on port 80. So how do we do that?As we did with the replicasetspreviously and a technique that you will see very oqen in kubernetes, we will use labels and selectors to link these together.  We know that the POD was created with a label. We need to bring that label into this service deﬁniCon ﬁle. 31/03/23\\n94', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 103}),\n",
              " Document(page_content='So we have a new property in the spec secCon and that is <click> selector. Under the selector provide a list of labels to idenCfy the POD. <click> For this refer to the pod-deﬁniCon ﬁle used to create the POD. <click> Pull the labels from the pod-deﬁniCon ﬁle and place it under the selector secCon. This links the service to the pod. <click> Once done create the service using the kubectlcreate command and input the service-deﬁniCon ﬁle and there you have the service created.To see the created service, run the kubectlget services command that lists the services, their cluster-ipand the mapped ports. The type is NodePortas we created and the port on the node automaCcally assigned is 32432. We can now use this port to access the web service using curl or a web browser. \\n95Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud>_apiVersion: kind:metadata:spec:service-definition.ymlv1Servicename: web-servicetype: NodePortports:-targetPort: 80port: 80nodePort: 30008selector:$kubectlcreate –f service-definition.ymlservice \"web-service\" created$kubectlget servicesNAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGEkubernetes      ClusterIP10.96.0.1        <none>        443/TCP        16dweb-service     NodePort10.106.127.123   <none>        80:30008/TCP   5m$ curl http://192.168.1.2:30008\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 104}),\n",
              " Document(page_content='So far we talked about a service mapped to a single POD. But that’s not the case all the time, what do you do when you have multiple PODs? <click>  In a production environment you have multiple instances of your web application running for high-availability and load balancing purposes. In this case we have multiple similar PODs running our web application. <click> They all have the same labels with a key name set to redis-pod. The same label is used as a selector during the creation of the service. So when the service is created, it looks for matching PODs with the labels and finds 3 of them. <click> The service then automatically selects all the 3 PODs as endpoints to forward the external requests coming from the user. You don’t have to do any additional configuration to make this happen. <click> And if you are wondering what algorithm it uses to balance load, it uses a random algorithm.  Thus, the service acts as a built-in load balancer to distribute load across different PODs. \\n96Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.4\\nNode8080808030008Algorithm: RandomSessionAffinity: Yes\\nname: redis-pod\\nname: redis-pod\\nname: redis-pod\\nname: redis-pod\\npod10.244.0.480', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 105}),\n",
              " Document(page_content='And ﬁnally, lets look at what happens when the PODs are distributed across mulCple nodes. In this case we have the web applicaCon on PODs on separate nodes in the cluster. When we create a service , without us having to do ANY kind of addiConal conﬁguraCon, <click> kubernetescreates a service that spans across all the nodes in the cluster and maps the target port to the SAME NodePorton all the nodes in the cluster. <click> This way you can access your applicaCon using the IP of any node in the cluster and using the same port number which in this case is 30008.To summarize –in ANY case weather it be a single pod in a single node, mulCple pods on a single node, mulCple pods on mulCple nodes, the service is created exactly the same without you having to do any addiConal steps during the service creaCon. When PODs are removed or added the service is automaCcally updated making it highly adapCve. Once created you won’t typically have to make any addiConal conﬁguraCon changes.\\n97Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudNode\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.4\\n80808030008Algorithm: RandomSessionAffinity: Yes\\nNode\\npod10.244.0.2\\npod10.244.0.3\\npod10.244.0.4\\n80808030008', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 106}),\n",
              " Document(page_content=\"It's time for labs for services. Click on the link to go directly to the labs. If you haven't enrolled already enroll for free.  In this lab you will work on creating services to expose applications within and outside a kubernetescluster. https://kodekloud.com/topic/labs-pods-with-yaml/\\n98Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudHands-On Labs -Serviceshttps://kode.wiki/kubernetes-labs\\n\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 107}),\n",
              " Document(page_content='99Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 108}),\n",
              " Document(page_content='So we just saw how the voting application works on Docker. Let’s now see how to deploy it on Kubernetes. So it’s very important to have a clear idea of what we are trying to achieve and plan accordingly before getting started. So we already know how the applications works, and it’s a good idea to write down what we plan to do.So our goal is to deploy these containers on a Kubernetes cluster, then enable connectivity between the containers so that the applications can access the databases and then enable external access for the external facing applications, which are voting and result app.  So how do we go about this?We know that we cannot deploy containers directly on Kubernetes, we learned that the smallest object we can create on a Kubernetes cluster is a POD. So we must deploy these applications as PODs on our Kubernetes cluster. Or we could deploy as replicasetsor deployments. But first we will stick to pods, and later we will see how to easily convert that to a deployment. So once the PODs are deployed the next step is to enable connectivity between the services. It’s important to first know what the connectivity requirements are. We must be very clear about what application 100Access Labs at: hjps://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud54328080\\n6379PODServicePODServicePODPODresult-appPODvoting-appredispostgresworker\\nServiceServiceGoals:1.Deploy Containers2.Enable Connectivity3.External AccessSteps:1.Deploy PODs2.Create Services (ClusterIP)1.redis2.db3.Create Services (NodePort)1.voting-app2.result-app\\nprogram.cs\\napp.py\\nserver.js', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 109}),\n",
              " Document(page_content='requires access to what services. We know that the redisdatabase is accessed by the voting-app and the worker app. The voting app saves the vote to the redisdatabase and the worker app reads the vote from the redisdatabase. We know that the PostgreSQL database is accessed by the worker app to update it with the total count of votes. And it’s also accessed by the result-app to read the total count of votes to be displayed in the result web page in a browser.We know that the voting app is accessed by the external users, the voters and the result app is also accessed by the external users to view the results. So most of the components are being accessed by another component, except for the worker app. Note that the worker app is not being accessed by anyone. The worker app simply reads the count of votes from redisand updates the total count on the postgresqldatabase. None of the other components nor the external users ever access the worker app. While the voting-app has a python web server that listens on port 80, and the result-app has a webserver that listens on port 80, and the redisdatabase has a service that listens on port 6379, and the postgresqldatabase has a service that listens on port 5432, the worker app has no service. Because it’s just a worker and is not accessed by any other service or external users. So keep that in mind.So how do you make one component accessible by another? Say for example how do you make the redisdatabase accessible by the voting app? Should the voting-app use the IP address of the redispod? No because that can change if the pod restarts. The right way to do it is to use a service. We learned that a service can be used to expose an application to other applications or users for external access. So we will create a service for the redispod so that it can be accessed by the voting-app and the worker app. We will call it a redisservice and it will be accessible anywhere within the cluster by the name of the service -redis. Why is that name important? The source code within the voting-app and the woker-app are hardcoded to point to a redisdatabase running on a host by the name redis. So it’s important to name your service as redis. So that these applications can connect to the redisdatabase. And this is not a best practice to hard code stuff like this within the source code of application, instead you should be using environment variables or something. But for the sake of simplicity we will just follow this approach.Now, these services are not to be accessed outside the cluster, so they should be of the type ClusterIP.We will follow the same step of creating a service for the Postgresqlpod so that the postgresqlDB can be accessed by the worker and the result-app. So what should we 31/03/23\\n100', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 110}),\n",
              " Document(page_content='name the postgresqlservice? If you look at the source code of the result-app and the worker app you will see that they are looking for a database at address db. So the service we create for postgresqlshould be named db.  Also note that while connecting to the database the worker and result apps pass in a user name and password to connect to the database. Both of which are postgres. So when we deploy the postgresdbpod we must make sure that we set that for it. The next task is to enable external access. For this we saw that we could use the service type NodePort. So we create services for voting-app and result app and set their type to NodePort. We could decide on what port we are going to make them available. So we are done and we have the high level steps ready.So to summarize we will be deploying 5 pods in total and we have 4 services, one for redisanother for postgresboth of which are internal services. So they are of type ClusterIP. We then have external facing services for voting app and result app. However we have no service for the worker pod. This is because it is not running any service that must be accessed by another application or external users. It is just a worker process that reads from one database and updates another. So it does not require a service. I say that again as that’s a common question I get when we talk about services, why does this worker not require a service. A service is only required if the application has some service –like a web server or database server -that needs to be exposed.31/03/23\\n100', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 111}),\n",
              " Document(page_content='Before we get started with the deployment note that we we will be using the following docker images for these applicaCons. These images are built from a fork of the original developed at the dockersamplesrepository. The image names are kodekloud/examplevoCngapp_vote:v1 worker:v1, result:v1 and for the databases we will use the oﬃcial redisand postgresqlones.So that’s it for now and we will see this in acCon in the upcoming demo.\\n101Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudPODServicePODServicePODPODresult-appPODvoting-appredispostgresworker\\nkodekloud/examplevotingapp_vote:v1kodekloud/examplevotingapp_result:v1\\nkodekloud/examplevotingapp_worker:v1\\nredispostgresqlSteps:1.Deploy PODs2.Create Services (ClusterIP)1.redis2.db3.Create Services (NodePort)1.voting-app2.result-app', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 112}),\n",
              " Document(page_content='So this is what we saw in the last demo. We deployed PODs and services to keep it really simple. But this has its own challenges. Deploying PODs doesn’t help us scale our applicaCon easily. If you wanted to update the image used in the applicaCon then your applicaCon will have to be taken down while a new pod is created. The right approach is to use Deployments to deploy an applicaCon. \\n102Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudPODServicePODServicePODPODresult-appPODvoting-appredisdbworker\\nServiceService', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 113}),\n",
              " Document(page_content='Let us now improvise our setup using Deployments. We chose deployments over ReplicaSetsas Deployments automaCcally create replica sets as required and it can help us perform rolling updates and roll backs and maintain a record of revisions and the cause of change as we have seen in the previous demos. Deployments are the way to go. So we add more PODs for the front end applicaCons voCng-app and result-app by creaCng a deployment with 3 replicas. We also encapsulate databases and worker applicaCons in deployments. Let’s take a look at that now.\\n103Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudDeploymentDeploymentDeploymentDeploymentDeploymentPODPOD\\nPODPODresult-appPODvoting-appredisdbworker\\nServiceServiceServiceServicePODvoting-app\\nPODvoting-app\\nPODresult-app\\nPODresult-app\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 114}),\n",
              " Document(page_content='So here we are at the end of this crash course. I hope you enjoyed the course. \\n104Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 115}),\n",
              " Document(page_content=\"We've covered containers, pods, replicasets, deployments and services in this course and also deployed an example voting application. However, that's only the tip of the iceberg. There's a lot more. \\n105Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudDeploymentReplicaSetPodsServices\\nTroubleshootingSetupUpgradesNetworkingAuto-ScalingMonitoringBackupsStorageDesign\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 116}),\n",
              " Document(page_content='The different ways of provisioning a cluster, administering a cluster, maintaining and upgrading a cluster, logging and monitoring, security, backups, storage, networking, auto scaling, designing a kubernetescluster and much more.\\n106Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudDeploymentPodsServices\\nTroubleshootingSetupUpgradesNetworkingAuto-ScalingMonitoringBackupsStorageDesign', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 117}),\n",
              " Document(page_content='All of these are covered in our Kubernetes Learning Path. This involves –the CKAD –Certified Kubernetes Application Developer course, the CKA course –the certified  kubernetesadministrator, the CKS course –certified Kubernetes security specialist, and others like Helm, Kustomize, Istio etc. \\n107Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud[demo-kubernetnetes-learning-path]', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 118}),\n",
              " Document(page_content='108Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\n', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf', 'page': 119})]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Splitting/chunking"
      ],
      "metadata": {
        "id": "BRmwG3lMcXX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter =RecursiveCharacterTextSplitter(chunk_size= 1000, chunk_overlap=20)\n",
        "docs=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "u7ER8wH8Zyg9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKG3Uk7iZybU",
        "outputId": "fe47011e-4e86-4d0e-8971-6011f743e84f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs =docs[:3]"
      ],
      "metadata": {
        "id": "XE68XWslf0YO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "373LkBXuZyY0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Object"
      ],
      "metadata": {
        "id": "YpmCEvfkdZ3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings= OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "zPven-91ZyWE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0alYqQIZyTf",
        "outputId": "4bc67116-6e5f-4487-c043-9b3241dd4a7b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7ccb3b3db8b0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7ccb3b2a81c0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database Storage"
      ],
      "metadata": {
        "id": "M8hKm1Qwd1sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from langchain.vectorstores import Weaviate"
      ],
      "metadata": {
        "id": "A6-sPBL6ZyQs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth_config = weaviate.auth.AuthApiKey(api_key = WEAVIATE_API_KEY)\n",
        "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
        "\n",
        "client = weaviate.Client(\n",
        "    url = WEAVIATE_URL,\n",
        "    additional_headers = {\"X-OpenAI-Api-key\": OPENAI_API_KEY},\n",
        "    auth_client_secret = auth_config,\n",
        "    startup_period = 10\n",
        ")"
      ],
      "metadata": {
        "id": "UOXd973OZyNv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.is_ready()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S8LounYZyI0",
        "outputId": "a2491b36-12f9-4bd6-cf3a-4965b78280df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define input structure\n",
        "client.schema.delete_all()\n",
        "client.schema.get()\n",
        "schema = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"class\": \"Chatbot\",\n",
        "            \"description\": \"Documents for chatbot\",\n",
        "            \"vectorizer\": \"text2vec-openai\",\n",
        "            \"moduleConfig\": {\"text2vec-openai\": {\"model\": \"ada\", \"type\": \"text\"}},\n",
        "            \"properties\": [\n",
        "                {\n",
        "                    \"dataType\": [\"text\"],\n",
        "                    \"description\": \"The content of the paragraph\",\n",
        "                    \"moduleConfig\": {\n",
        "                        \"text2vec-openai\": {\n",
        "                            \"skip\": False,\n",
        "                            \"vectorizePropertyName\": False,\n",
        "                        }\n",
        "                    },\n",
        "                    \"name\": \"content\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "LBHCkDavZyGN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.schema.create(schema)"
      ],
      "metadata": {
        "id": "zfm2GgEPZyDc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=Weaviate(client,\"Chatbot\", \"content\", attributes=['source'])"
      ],
      "metadata": {
        "id": "CT3t2BBsZyA0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_meta_pair= [(doc.page_content, doc.metadata) for doc in docs]"
      ],
      "metadata": {
        "id": "6VEUP3TNd9OQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, meta= list(zip(*text_meta_pair))"
      ],
      "metadata": {
        "id": "yrs3gpR1d9Ln"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.add_texts(texts, meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyk0P8GHd9In",
        "outputId": "0e3c4736-5018-495f-bc66-53e1a93824de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3e77f67e-0479-4cf0-94bd-28ac96871a2e',\n",
              " '4a3e8414-8147-4bc4-a4b8-f3f4ccd23f68',\n",
              " '76d55775-3880-4df2-b48c-f650ba385a01']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\" tell me something about the kubernates\"\n",
        "\n",
        "docs=vectorstore.similarity_search(query, top_k=1)"
      ],
      "metadata": {
        "id": "-gAxY7U-d9GL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SfqHF6rd9D6",
        "outputId": "5bca34bd-9084-4fe6-fe93-b1876b72b980"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"We'll start with a quick introducCon to containers, and then we'll understand why you need container orchestraCon, what Kubernetes is, and then dive into Kubernetes concepts such as Pods, ReplicaSets, Deployments, Services and ﬁnally a project on deploying a micro-services applicaCon to a Kubernetes cluster. \\n2Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nContainers\\nKubernetes\\nKubernetes Cluster\\nPods\\nReplicaSets\\nDeployments\\nServices\\nProject\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf'}),\n",
              " Document(page_content=\"We'll start with a quick introducCon to containers, and then we'll understand why you need container orchestraCon, what Kubernetes is, and then dive into Kubernetes concepts such as Pods, ReplicaSets, Deployments, Services and ﬁnally a project on deploying a micro-services applicaCon to a Kubernetes cluster. \\n2Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloud\\nContainers\\nKubernetes\\nKubernetes Cluster\\nPods\\nReplicaSets\\nDeployments\\nServices\\nProject\", metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf'}),\n",
              " Document(page_content='In this course you are going to learn the absolute basics of Kubernetes. \\n1Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudkubernetes', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf'}),\n",
              " Document(page_content='In this course you are going to learn the absolute basics of Kubernetes. \\n1Access Labs at: https://kode.wiki/kubernetes-labs kodekloud.com\\n© Copyright KodeKloudkubernetes', metadata={'source': 'data/Kubernetes-Crash-Course-For-PDF-1.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "D_kdHnAfd9Aj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define chain\n",
        "chain = load_qa_chain(\n",
        "    OpenAI(),\n",
        "    chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "8J0xk5axd894"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create answer\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5tuy7X59d8xg",
        "outputId": "bb4d1cf0-7a20-4609-efb1-7b3c4b2aa2cf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Kubernetes is a popular open-source platform used for automating the deployment, scaling, and management of containerized applications. It allows for efficient management of container clusters and provides features such as self-healing, load balancing, and automatic rollbacks to ensure the smooth operation of applications in a production environment.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vEJTMo2bd8u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oQE9hrqtd8sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsEqdRxpd8pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SW2OR7qqd8mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSZT5fL2d8kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o09X885ed8hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBtsljJPd8fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VY9ucOY3d8c4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}